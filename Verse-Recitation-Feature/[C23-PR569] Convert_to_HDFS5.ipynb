{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["%%capture\n","!pip install datasets\n","!pip install transformers==4.28.0"],"metadata":{"id":"p0iL0tEeqeRr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"5bDd0kGszc1b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#latest wer=29\n","repo_name=\"zarko1231/model-baru-collab\""],"metadata":{"id":"ClK7Wr3rqiVa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from transformers import TFWav2Vec2ForCTC,Wav2Vec2Processor\n","\n","# Convert the PyTorch model to TensorFlow\n","tf_model = TFWav2Vec2ForCTC.from_pretrained(repo_name, from_pt=True)\n","processor = Wav2Vec2Processor.from_pretrained(repo_name)\n"],"metadata":{"id":"1lhPoMTuq4iU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the TensorFlow model HDFS5\n","save_dir = \"model\"\n","tf_model.save_pretrained(save_dir)\n","processor.save_pretrained(save_dir)\n"],"metadata":{"id":"TVC0l2mRrwAE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the model in SavedModel format Pb\n","save_dir = \"/content/modelpb\"\n","tf_model.save(save_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZlXP7rNyt0xj","executionInfo":{"status":"ok","timestamp":1686077802566,"user_tz":-420,"elapsed":194387,"user":{"displayName":"Mujadid Syahbana M181DSX1303","userId":"02342292025052622935"}},"outputId":"396ea097-a282-459b-a385-985ad6a43d48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as feature_extractor_layer_call_fn, feature_extractor_layer_call_and_return_conditional_losses, feature_projection_layer_call_fn, feature_projection_layer_call_and_return_conditional_losses, encoder_layer_call_fn while saving (showing 5 of 791). These functions will not be directly callable after loading.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28506,"status":"ok","timestamp":1686077936235,"user":{"displayName":"Mujadid Syahbana M181DSX1303","userId":"02342292025052622935"},"user_tz":-420},"id":"R351I9IQp_9D","outputId":"e922cc3a-6464-474c-fd1e-6faa514afcbb"},"outputs":[{"output_type":"stream","name":"stderr","text":["\n","TFWav2Vec2ForCTC has backpropagation operations that are NOT supported on CPU. If you wish to train/fine-tine this model, you need a GPU or a TPU\n","Some layers from the model checkpoint at /content/model were not used when initializing TFWav2Vec2ForCTC: ['dropout_98']\n","- This IS expected if you are initializing TFWav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFWav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFWav2Vec2ForCTC were not initialized from the model checkpoint at /content/model and are newly initialized: ['dropout_197']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["#load HDFS5 from local\n","my_model_local=\"/content/model\"\n","processor_local = Wav2Vec2Processor.from_pretrained(my_model_local)\n","model_local = TFWav2Vec2ForCTC.from_pretrained(my_model_local)"]},{"cell_type":"code","source":["model_local.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rqyeb9lP0lFj","executionInfo":{"status":"ok","timestamp":1686077956976,"user_tz":-420,"elapsed":353,"user":{"displayName":"Mujadid Syahbana M181DSX1303","userId":"02342292025052622935"}},"outputId":"a5e2739e-dee0-4c9f-8297-16e0e6df389f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"tf_wav2_vec2_for_ctc_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," wav2vec2 (TFWav2Vec2MainLay  multiple                 315438720 \n"," er)                                                             \n","                                                                 \n"," dropout_197 (Dropout)       multiple                  0         \n","                                                                 \n"," lm_head (Dense)             multiple                  48175     \n","                                                                 \n","=================================================================\n","Total params: 315,486,895\n","Trainable params: 315,486,895\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]}]}